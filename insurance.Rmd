---
title: "Insurance Classification and Prediction"
author: "Sean Connin"
output:
  html_document: 
    toc: true
    toc-title: ""
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
    theme: united
    highlight: tango
  pdf_document: default
---

```{r setup, include=FALSE}

# set global options

knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE)

```
### Project Description

The purpose of this work is to estimate the probability that an individual (seeking auto insurance) will be in an accident and then estimate the potential cost of that claim. A synthetic data set of ~ 8000 observations will be used to construct predictive models for this purpose. The use of synthetic data permits model development absent proprietary information. It also provides a heuristic for quantitative reasoning and decision-making.

The data include the following variables: 


| Variable             | Description                                  |
|----------------------|----------------------------------------------|
| Target FLAG          | Was car in crash? 1=Yes, 0=No                |
| Target_ AMT          | If crash, what was the cost                  |
| AGE                  | Age of driver                                |
| BLUEBOOK             | Value of vehicle                             |
| CAR_AGE              | Age  of car                                  |
| CAR_TYPE             | Type of car                                  |
| CAR_USE              | Vehicle use                                  |
| CLM_FREQ             | # Claims (past 5 yrs)                        |
| EDUCATION            | Max educational level                        |
| HOMEKIDS             | # Children at home                           |
| HOME_VAL             | Home value                                   |
| INCOME               | Annual income                                |
| JOB                  | Job category                                 |
| KIDSDRIVE            | # Driving children                           |
| MSTATUS              | Martial status                               |
| MVR_PTS              | Motor vehicle record points                  |
| OLDCLAIM             | Total claims (past 5 yrs)                    |
| PARENT1              | Single parent                                |
| RED_CAR              | A red car                                    |
| REVOKED              | License revoked (past 7 yrs)                 |
| SEX                  | Gender                                       |
| TIF                  | Time as customer                             |
| TRAVTIME             | Distance to work                             |
| URBANICITY           | Home/work area                               |
| YOJ                  | Years on job                                 |


```{r}

library(tidyverse)
library(janitor)
library(magrittr)
library(flextable)
library(dlookr) # eda
library(mice)
library(ggpubr) # creates a wrapper for plotting a list
library(viridis)
library(broom) # creates a tidy data frame from statistical test results
#library(pscl)

library(InformationValue) # optimize threshold
library(MASS) #partial likelihood test for model fit comparisons
library(caret) # conf matrix
library(ROCR) #roc curve
library(corrplot)
library(car)
#library(logistf)
```

```{r}

# read in data

path <- "https://raw.githubusercontent.com/sconnin/insurance_model/main/insurance_dataset.csv"

raw <- read_csv(path)

```


### Data Preparation

The step includes:

* creating a copy dataframe (df)
* basic cleaning operations
* conversion of variables to numeric type as appropriate
* conversion of character variables to factor in preparation for modeling
* releveling of select factor variables
* removal of any empty rows/cols or duplicate rows 
* removal of the index column for simplicity

Review of the dataframe structure confirms these changes

```{r}

df<-raw%>%
    
    clean_names%>% # initial clean of col names
    
    remove_empty(c("rows", "cols"))%>%  # remove any empty rows and cols
    
    distinct()%>%     # remove duplicate rows
    
    mutate_if(is_character, str_replace_all, '\\$|,|z_|<', '')%>%  # clean any special chars in character variables

    dplyr::select(-index)%>%  # remove index

    mutate_if(is_character, str_replace_all, "No|no",'N')%>%  
    
    mutate_if(is_character, str_replace_all, "Yes|yes",'Y')%>%
    
    mutate_if(is_character, str_replace_all, "Highly Urban/ Urban",'Urban')%>%
    
    mutate_if(is_character, str_replace_all, "Highly Rural/ Rural",'Rural')%>%
    
    mutate_at(vars(income, home_val, bluebook, oldclaim), funs(as.numeric))%>%   # correct variable type: char to numeric

    mutate_if(is.numeric, round)%>%  # round out our numerics
    
    mutate_if(is_character, ~(factor(.)))%>%  # convert all character variables to factor for modeling
    
    mutate(education = fct_relevel(education, c("High School", "Bachelors", "Masters", "PhD")))%>% # relevel to show educational attainment steps
    
    mutate(car_type = fct_relevel(car_type, c("Sports Car", "SUV", "Minivan, Van", "Pickup", "Panel Truck")))

str(df) # review structure of data set

```

### Variable distributions and frequency

Recall that the variable target_flag indicates whether or not an automobile was in an
accident (0 = No, 1 = Yes).

* target_flag (level = 0) includes 6008 observations and accounts for ~74% of the data.

* target_flag (level = 1) includes 2153 observations and accounts for ~26% of the data. 

Note that while the levels are unbalanced, the relative frequency of target_flag = 1
is well above that indicative of a rare event. 

```{r}

# subset levels of target_flag into new dataframes for analyses

target_0 <- df%>%
    dplyr::select(-target_amt)%>%
    filter(target_flag == 0) # obs not associated with automobile accidents

target_1 <- df%>%
    dplyr::select(-target_amt)%>%
    filter(target_flag == 1)  # obs associated with automobile accidents

# calculate the proportion of data in each subset of target_flag

df %>%
    group_by(target_flag) %>%
    summarise(n = n()) %>%
    mutate(freq = n / sum(n))%>%
    flextable()

```


There is one negative value (-3) for car_age that should be investigated.This may be 
a data entry error.



```{r}

# calculate basic univariate summaries (numeric variables) for each subset of target_flag    

target_0%>%
    dplyr::select(-target_flag)%>%
    diagnose_numeric()%>%
    dplyr::select(variables, min, mean, median, max, zero, minus, outlier)%>%
    flextable()%>%
    set_caption("Summary Statistics for Target_Flag = 0")

target_1%>%
    dplyr::select(-target_flag)%>%
    diagnose_numeric()%>%
    dplyr::select(variables, min, mean, median, max, zero, minus, outlier)%>%
    flextable()%>%
    set_caption("Summary Statistics for Target_Flag = 1")

#calculate percentage of zero values in numerical covariates for each level of target_flag

select_col<- as_mapper(~all(is.na(.)|.< 1)) # purrr mapper for possible downstream use

# note target_flag must be numerical type for the following to run

df%>%
    group_by(target_flag)%>%
    dplyr::select(where(is.numeric) & -target_amt)%>%
    summarise_each(~round(sum(.==0)/length(.)*100))%>%
    purrr::discard(select_col)%>%
    flextable()%>%
    set_caption("Percentage of Zeros in Covariates by Level of Target_Flag")

# calculate basic univariate summaries (categorical variables) for each subset of target_flag 

target_0%>%
    diagnose_category()%>%
    flextable(theme_fun = theme_booktabs())

target_1%>%
    diagnose_category()%>%
    flextable(theme_fun = theme_booktabs())





```
Correct obvious data entry error in working dataframe

```{r}

df$car_age[df$car_age < 0] <- NA


```


Assess skewness and normality

skewed data - target_flag, kidsdriv, homekids, yoj, income, oldclaim, clm_freq, 
mvr_pts"


```{r}

# evaluate and rank departures from normality for numerical vars

df %>%
    as.data.frame()%>%
    dplyr::select(-target_amt, target_flag)%>%
    normality() %>%
    filter(p_value <= 0.01) %>%
    arrange(abs(p_value))

#identify skewness in covariates across levels of target_flag

target_0%>%find_skewness(index=FALSE, thres=TRUE) 
target_1%>%find_skewness(index=FALSE, thres=TRUE)

# identify potential transformations to address skew, this does not resolve high 0 counts

df%>%
    dplyr::select(age, yoj, income, home_val, travtime, bluebook, tif, oldclaim, car_age)%>%
    plot_normality()

```

Evaluate outliers

percentage of outliers > 5%: kidsdriv, homekids, yoj 

```{r}

# identify percentage of outliers for each covariate across levels of target_flag
# calc ratio_means = mean val of outliers/total mean    

diagnose_outlier(target_0) %>%
    filter(outliers_ratio > 5)%>%
    mutate(ratio_means= outliers_mean/with_mean)%>%
    arrange(desc(ratio_means))%>%
    dplyr::select(variables, outliers_ratio, ratio_means)%>%
    flextable()%>%
    set_caption("Outlier Summary: Target_Flag = 0")

diagnose_outlier(target_1) %>%
    filter(outliers_ratio > 5)%>%
    mutate(ratio_means= outliers_mean/with_mean)%>%
    arrange(desc(ratio_means))%>%
    dplyr::select(variables, outliers_ratio, ratio_means)%>%
    flextable()%>%
    set_caption("Outlier Summary: Target_Flag = 1")
```

**Missing values**

Our dataset includes missing observations in one categorical variable (job) and six
numerical variables (car_age, home-val, yoj, income, age). Across the variables the
extent of missingness is < 6.5% of the total observations. Before making adjustments to
address missingness, it may be helpful to assess collinearity among the covariates. 


```{r }

#basic missing table
    
target_0%>%
    diagnose()%>%
    dplyr::select(-unique_count, -unique_rate)%>%
    filter(missing_count>0)%>%
    arrange(desc(missing_count))%>%
    flextable()

target_1%>%
    diagnose()%>%
    dplyr::select(-unique_count, -unique_rate)%>%
    filter(missing_count>0)%>%
    arrange(desc(missing_count))%>%
    flextable()

# plot missing data to visualize cumulative percentages and col intersections

df %>% 
  plot_na_pareto(only_na = TRUE)

df%>%
    plot_na_intersect()  

```
Impute numerical values 

Note: imputation method determined through iterative trials

```{r}

#impute numerical vars using dlookr, methods have been preselected based on initial plots.

#car_age

car_age<-imputate_na(df, car_age, target_flag, method = "mice", seed = 999)

plot(car_age)+theme_minimal()+theme(legend.position = "top")

summary(car_age)


#home_val


home_val<-imputate_na(df, home_val, target_flag, method = "rpart")

plot(home_val)+theme_minimal()+theme(legend.position = "top")

summary(home_val)

#yoj


yoj<- imputate_na(df, yoj, target_flag, method = "rpart")

plot(yoj)+theme_minimal()+theme(legend.position = "top")

summary(yoj)

# income

income<-imputate_na(df, income, target_flag, method = "rpart")

plot(income)+theme_minimal()+theme(legend.position = "top")

summary(income)

#age

age<-imputate_na(df, age, method = "rpart")

plot(age)+theme_minimal()+theme(legend.position = "top")

summary(age)

temp<-cbind(car_age, home_val, yoj, income, age)
temp%<>%as.data.frame(temp)

df%<>%dplyr::select(!c(car_age, home_val, yoj, income, age))%>%
    cbind(temp)

df%<>%mutate_if(is.numeric, round)

```

Impute Categorical Variables - job

```{r}

job<-imputate_na(df, job, method = "mice", seed = 999)

plot(job)+theme_minimal()+theme(legend.position = "top")


# combine into new dfb

df<-df%>%
    dplyr::select(!job)

df<-cbind(df,job)

df$job<-factor(df$job)

```
Save csv with imputed values 

```{r}

df%<>%mutate_at(vars(target_flag), funs(factor)) # convert target_flag to factor

write.csv(df, 'df_clean.csv', row.names=FALSE)

```

**Assess Colinearity: Pairwise Comparisons**

Pairwise comparisons provide a method to identify collinear relationships between
covariates. Variables that display high collinearity (e.g., <> .50) may be redundant 
for modeling purposes (i.e., the total variance explained by each variable).

To refine the analyses, pairwise comparisons are assessed independently for the 
two levels of the target variable. 

Results:

* There are no pairwise correlations beyond the threshold (-.50, .50) for the target_flag = 1 subset
* home_value and income have a positive coeff. of correlation of ~ 0.59
* clm_freq and oldclaim have a positive coeff. of correlation of ~ 0.52

Both home_value and income have similar levels of missing data. An argument can be
made for dropping either home-value or income from the dataset in order to simplify 
the feature selection process. This is also true for clm_freq and oldclaim, although
less clear cut. 


```{r}

#assess covariance in the absence of zero values in numerical cols

df%>%
    filter_if(is.numeric, all_vars((.) != 0))%>%
    correlate()%>%
    filter(coef_corr > .5 | coef_corr < -.5)%>% # set thresholds to limit output 
    flextable()

# plot relationship between numerical covariates (w/o zero values for clarity) beyond the threshold coef_corr 

df %>%
    filter(income != 0 & home_val != 0)%>% 
    target_by(income) %>%
    relate(home_val) %>%
    plot()
    

df %>%
    filter(clm_freq != 0 & oldclaim != 0)%>%
    target_by(clm_freq) %>%
    relate(oldclaim) %>%
    plot()

df %>%
    filter(home_val != 0 & car_age != 0)%>%
    target_by(home_val) %>%
    relate(car_age) %>%
    plot()

# plot relationship between numerical and factors for select vars

df %>% 
  target_by(income) %>%      
  relate(job) %>% 
  plot()

df%>%kruskal.test(income~job) # assess covariance with Kruskal-Wallis rank sum test where > 1 categorical level

```

# Review categorical vars in relation to target

Note: target_flag needs to be a factor var for mosaic plotting

Note: use all_of to avoid ambiguity in selecting external vector - https://tidyselect.r-lib.org/reference/faq-external-vector.html

Findings:

```{r }

df_factor<-df%>%
    dplyr::select(where(is.factor))

target <- all_of(names(df_factor)[1]) # set name for target_flag
covariates <- all_of(names(df_factor)[2:11]) # set names for factor covariates

#create mosaic plots


(plots<-covariates%>%map(function(covariates) df%>%target_by(target)%>%relate(covariates)%>%plot()))

```
# Review numerical vars in relation to target

```{r}

str(df)

num_box<-select_if(df, is.numeric)%>%
    dplyr::select(-target_amt)

num_box<-cbind(df$target_flag, num_box)%>%
    rename(target_flag = 'df$target_flag')


response = names(num_box)[1] #target_flag
response = purrr::set_names(response)

explain <- names(num_box)[2:14] #explanatory variables
explain = purrr::set_names(explain)

box_fun = function(x) {
    ggplot(num_box, aes_string(x = x, y = 'target_flag') ) +
    geom_boxplot(aes(fill = target_flag, alpha = 0.4), outlier.color =
    'red', show.legend = FALSE)+
    scale_fill_viridis(discrete = TRUE, option = "E")+
    coord_flip()+
    theme_classic()
}

b_plots<-map(explain, ~box_fun(.x)) #creates a list of plots

ggarrange(plotlist=b_plots, height = .5, ncol = 3)


```
Make final variable selections -> create base_df for modeling


```{r}

base_df<-df%>%
    dplyr::select(-home_val, -target_amt)  # variance in these fields explained by income

base_df%<>%
    mutate(job = (fct_collapse(job,
                 not_white_collar = c("Student", "Blue Collar", "Home Maker", "Clerical", "Manager"),
                 white_collar = c("Doctor", "Lawyer", "Professional"))))

write.csv(base_df, 'base_df.csv', row.names=FALSE)    
```
Create training and test dataframes

```{r}
#base_df<-read.csv('base_df.csv') # hold here to assist model dev 

base_df%>%count(target_flag)%>%
    mutate(frequency = n/sum(n))%>%
    flextable()  #0=6008, 1=2153

ones <- base_df%>%
    filter(target_flag == "1")

zeros <-base_df%>%
    filter(target_flag =="0")

set.seed(1234)

input_ones <- sample(1:nrow(ones), 0.7*nrow(ones))
input_zeros <- sample(1:nrow(zeros), 0.7*nrow(ones))

train_ones <- ones[input_ones, ]
train_zeros <- zeros[input_zeros, ]

train_df<-rbind(train_ones, train_zeros)

test_ones <- ones[-input_ones,]
test_zeros <- zeros[-input_zeros,]

test_df <- rbind(test_ones, test_zeros)

#check counts and frequencies of target_flag for train set and test set - helpful when comparing to confusion matrix

train_df%>%count(target_flag)%>%
    mutate(frequency = n/sum(n))%>%
    flextable()

test_df%>%count(target_flag)%>%
    mutate(frequency = n/sum(n))%>%
    flextable()

```

##Build Models##

**Null Model: logistic regression**

```{r}

null<-glm(target_flag ~ 1, family = binomial, train_df)

summary(null)

```


**Full Model: logistic regression**

```{r}

full<-glm(target_flag ~ ., family = binomial, train_df)

summary(full)

```


**Reduced Model: logistic regression **

```{r}

#build reduced model


reduced <- glm(target_flag ~ .,family='binomial', train_df) 

reduced<-step(reduced, trace=0) # use Akiaike step, trace 0 prevents intermediate printing

summary(reduced)

```
**Diagnostics: reduced model**

The ROC curve shows the tradeoff between true positive rate and false positive rate across all cutoff values.

Note: InformationValue:confusionMatrix -- wants predicts and obs to be numerical, in caret they should be factor!

```{r}

# collect predicted percentages

predicted<-predict(reduced,reduced_df,type='response')

# find optimal threshold to minimize misclassification

(optimal<- optimalCutoff(train_df$target_flag, predicted, optimiseFor = "misclasserror"))  # 0.51

# calculate training classification error with .51 threshold --> 0.2595

misClassError(train_df$target_flag, predicted,  threshold = optimal)

# convert predicted to 0, 1 values based on threshold

predicts<-ifelse(predicted >= optimal, 1, 0)

# subset actuals and predicts as numeric for confusion matrix

actuals<-as.numeric(as.character(train_df$target_flag))

(InformationValue::confusionMatrix(actuals, predicts, threshold = optimal)) 

#Calculate related metrics

auc<-AUROC(actuals, predicted) # -->.81

InformationValue::sensitivity(actuals, predicts, threshold = optimal) # recall: true positive rate
InformationValue::specificity(actuals, predicts, threshold = optimal) #false positive rate
InformationValue::precision(actuals, predicts, threshold = optimal) # prop of predicted ones /prop total ones

youdensIndex(actuals, predicts, threshold = optimal) # 0.48 accounts for both false-positive and false-negative rates

Concordance(actuals, predicts) # predictive power  ---> .548

ks_plot(actuals, predicts) #cum perc of ones captured by the model against that expected random

ks_stat(actuals, predicts) #Kolmogorov-Smirnov statistic - maximum difference between the cumulative true positive and cumulative false positive rate

# Construct ROC curve: note actuals, predicts, predicted as vectors)

pred <- ROCR::prediction(predicted, actuals)
perf <- ROCR::performance(pred, "tpr", "fpr")
plot(perf, colorize = TRUE, main = "ROC curve for logistic regression on insurance data")

#AUC curve

plotROC(actual, predicted)

```

***Reduced Model: Assess  overdispersion***

- we are within tolerable levels of dispersion

```{r}

# evaluate using deviance and quasibinomial comparison

deviance(reduced)/df.residual(reduced) # if considerably greater than one we should be concerned

# dble check with two model fit

quasi_model <-  glm(target_flag ~ .,family='quasibinomial', base_df) # note: using base_df
  
pchisq(summary(quasi_model)$dispersion * reduced$df.residual,
 reduced$df.residual, lower = F)  
```
***Reduced: Check linearity of numerical vars vs. logit***

Linearity is questionable for yoj, oldclaim

Note clustering in oldclaim - consider turning into 3-level factor?

```{r}

#create a dataframe for linearity analysis

reduced_df<-train_df

reduced_df$predicted<-predict(reduced,train_df,type='response') # add predicted

reduced_df%<>%mutate(logit = log(predicted/(1-predicted))) # add logit


# check linearity btwn numerical predictors and logit

with(reduced_df, scatter.smooth(travtime, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(reduced_df, scatter.smooth(tif, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(reduced_df, scatter.smooth(mvr_pts, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(reduced_df, scatter.smooth(income, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(reduced_df, scatter.smooth(homekids, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(reduced_df, scatter.smooth(oldclaim, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(reduced_df, scatter.smooth(clm_freq, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
with(reduced_df, scatter.smooth(bluebook, logit, lpars = list(col = "red", lwd = 3, lty = 3)))


```

#Reduced Model: evaluate outliers and infuential obs

computes the standardized residuals (.std.resid) and the Cook’s distance (.cooksd) using the R function augment() [broom package]

See: http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/

Findings:

Cooks distance indicates several standout obs (3722, 3592, 6501) but no influential points (id. D >1.0)

There are no obs has std residual beyond 3 stdev: 5101


```{r}

# Extract model results

reduced$data <- augment(reduced) %>% 
  mutate(index = 1:n()) 

#top 10 largest values

reduced$data %>% top_n(10, .cooksd)

plot(reduced, which = 4, id.n = 3)  # keep an eye on obs > 4/n 

#plot std residuals

ggplot(reduced$data, aes(index, .std.resid)) + 
  geom_point(aes(color = target_flag), alpha = .5) +
  theme_bw()

#Filter potential influential data points with abs(.std.res) > 3

reduced$data %>% 
  filter(abs(.std.resid) > 3)
```
***Model 1 Assess multicollinearity***

Findings: no problems with collinearity

```{r}

car::vif(reduced)
```

***Reduced Model: check std residuals for independence: resids vs. logit ***

We see some possible pattern (curvature) that might indicate misclassification but its unclear 

```{r }

resid_df<-train_df%>%mutate('residuals' = residuals(reduced), linpred = predict(reduced))

bins<- group_by(resid_df, cut(linpred, breaks=unique(quantile(linpred, (1:100)/101))))

diag<-summarize(bins, residuals=mean(residuals), linpred = mean(linpred))

plot(residuals~linpred, diag, xlab = "linear predictor")


```
**Transfomed Model**


reduced model = target_flag ~ kidsdriv + parent1 + mstatus + education + 
    travtime + car_use + bluebook + tif + car_type + oldclaim + 
    clm_freq + revoked + mvr_pts + urbanicity + income + age

We will log transform income, tif, bluebook, travtime oldclaim


```{r fig.align='center', fig.height=10,fig.width=10, message = FALSE}


#build model with transformed vars

trans <- glm( target_flag ~ kidsdriv + parent1 + mstatus + education + 
    log(travtime) + car_use + log(bluebook) + sqrt(tif) + car_type + (oldclaim) + 
    clm_freq + revoked + mvr_pts + urbanicity + sqrt(income) + age, family='binomial', train_df)

trans<-step(trans, trace=0) 

summary(trans)


```
**Transformed Model: diagnostics **

```{r}

# collect predicted percentages

trans_predicted<-predict(trans,train_df,type='response')

# find optimal threshold to minimize misclassification

(trans_optimal<- optimalCutoff(train_df$target_flag, trans_predicted, optimiseFor = "misclasserror"))  # 0.51

# calculate training classification error with .51 threshold --> 0.2588

misClassError(train_df$target_flag, trans_predicted,  threshold = trans_optimal)

# convert predicted to 0, 1 values based on threshold

trans_predicts<-ifelse(trans_predicted >= trans_optimal, 1, 0)

# subset actuals and predicts as numeric for confusion matrix

trans_actuals<-as.numeric(as.character(optimum_df$target_flag))

(InformationValue::confusionMatrix(actuals, predicts, threshold = optimal)) 

#Calculate related metrics

auc<-AUROC(trans_actuals, trans_predicted) # -->.81
InformationValue::sensitivity(actuals, predicts, threshold = optimal) # recall: true positive rate
InformationValue::specificity(actuals, predicts, threshold = optimal) #false positive rate
InformationValue::precision(actuals, predicts, threshold = optimal) # prop of predicted ones /prop total ones
youdensIndex(actuals, predicts, threshold = optimal) # 0.48 accounts for both false-positive and false-negative rates

Concordance(actuals, predicts) # predictive power  ---> .548

ks_plot(actuals, predicts) #cum perc of ones captured by the model against that expected random

ks_stat(actuals, predicts) #Kolmogorov-Smirnov statistic - maximum difference between the cumulative true positive and cumulative false positive rate

# Construct ROC curve: note actuals, predicts, predicted as vectors)

pred <- ROCR::prediction(predicted, actuals)
perf <- ROCR::performance(pred, "tpr", "fpr")
plot(perf, colorize = TRUE, main = "ROC curve for logistic regression on insurance data")

#AUC curve

plotROC(actual, predicted)
```






