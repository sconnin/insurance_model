
---
title: "Insurance Classification and Prediction"
date: "1/11/22"
author: "Sean Connin"
output:
  html_document: 
    toc: true
    toc-title: ""
    toc_depth: 3
    toc_float:
      collapsed: false
      smooth_scroll: false
    theme: united
    highlight: tango
  pdf_document: default
---

```{r setup, include=FALSE}

# set global options

knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message = FALSE)

```
##Project Description##

The purpose of this work is to estimate the probability that an individual (seeking auto insurance) will be in an accident and then estimate the potential cost of that claim. A synthetic data set of ~ 8000 observations will be used to construct predictive models for this purpose. The use of synthetic data permits model development absent proprietary information. It also provides a heuristic for quantitative reasoning and decision-making.

A logistic classifier binary target variable (target_flag) 


dataset includes a class membership score for the target variable (target_flag), where 1 = Yes (confirmed crash) and 0 = No

scores for each observation (an individua1) 

For these purposes, t 

The data include the following variables: 


| Variable             | Description                                  |
|----------------------|----------------------------------------------|
| Target FLAG          | Was car in crash? 1=Yes, 0=No                |
| Target_ AMT          | If crash, what was the cost                  |
| AGE                  | Age of driver                                |
| BLUEBOOK             | Value of vehicle                             |
| CAR_AGE              | Age  of car                                  |
| CAR_TYPE             | Type of car                                  |
| CAR_USE              | Vehicle use                                  |
| CLM_FREQ             | # Claims (past 5 yrs)                        |
| EDUCATION            | Max educational level                        |
| HOMEKIDS             | # Children at home                           |
| HOME_VAL             | Home value                                   |
| INCOME               | Annual income                                |
| JOB                  | Job category                                 |
| KIDSDRIVE            | # Driving children                           |
| MSTATUS              | Martial status                               |
| MVR_PTS              | Motor vehicle record points                  |
| OLDCLAIM             | Total claims (past 5 yrs)                    |
| PARENT1              | Single parent                                |
| RED_CAR              | A red car                                    |
| REVOKED              | License revoked (past 7 yrs)                 |
| SEX                  | Gender                                       |
| TIF                  | Time as customer                             |
| TRAVTIME             | Distance to work                             |
| URBANICITY           | Home/work area                               |
| YOJ                  | Years on job                                 |


```{r}

# Import libraries

library(tidyverse)
library(janitor)
library(magrittr)
library(flextable)
library(dlookr) # eda
#library(mice)
library(patchwork) # easy plot layout
library(ggpubr) # creates a wrapper for plotting a list
#library(viridis)
library(broom) # creates a tidy data frame from statistical test results


library(InformationValue) # optimize threshold
#library(MASS) #partial likelihood test for model fit comparisons
library(caret) # conf matrix
library(ROCR) #roc curve
#library(corrplot)
library(car)
#library(logistf)
```

```{r}

# Read in data

path <- "https://raw.githubusercontent.com/sconnin/insurance_model/main/insurance_dataset.csv"

raw <- read_csv(path)

```
##1. Data Processing##

**1a. Clean and Reformat Data**

This step includes:

* Creating a copy dataframe (df)
* Basic cleaning operations
* Conversion of variables to numeric type as appropriate
* Conversion of character variables to factor in preparation for modeling
* Releveling of select factor variables
* Removal of any empty rows/cols or duplicate rows 
* Removal of the index column for simplicity

Review of the dataframe structure confirms these changes

```{r}

# Copy data into working dataframe for downstream use

df<-raw%>%
    
    clean_names%>% # initial clean of col names
    
    remove_empty(c("rows", "cols"))%>%  # remove any empty rows and cols
    
    distinct()%>%     # remove duplicate rows
    
    mutate_if(is_character, str_replace_all, '\\$|,|z_|<', '')%>%  # clean any special chars in character variables

    dplyr::select(-index)%>%  # remove index

    mutate_if(is_character, str_replace_all, "No|no",'N')%>%  
    
    mutate_if(is_character, str_replace_all, "Yes|yes",'Y')%>%
    
    mutate_if(is_character, str_replace_all, "Highly Urban/ Urban",'Urban')%>%
    
    mutate_if(is_character, str_replace_all, "Highly Rural/ Rural",'Rural')%>%
    
    mutate_at(vars(income, home_val, bluebook, oldclaim), funs(as.numeric))%>%   # correct variable type: char to numeric

    mutate_if(is.numeric, round)%>%  # round out our numerics
    
    mutate_if(is_character, ~(factor(.)))%>%  # convert all character variables to factor for modeling
    
    mutate(education = fct_relevel(education, c("High School", "Bachelors", "Masters", "PhD")))%>% # relevel to show educational attainment steps
    
    mutate(car_type = fct_relevel(car_type, c("Sports Car", "SUV", "Minivan, Van", "Pickup", "Panel Truck")))

str(df) # review structure of data set

```

**1b. Tabulate Count and Frequency of Target Variable**

Recall that the variable target_flag indicates whether or not an automobile was in an
accident (0 = No, 1 = Yes).

* target_flag (level = 0) includes 6008 observations and accounts for ~74% of the data.

* target_flag (level = 1) includes 2153 observations and accounts for ~26% of the data. 


```{r}

# Subset levels of target_flag into new dataframes for analyses

target_0 <- df%>%
    dplyr::select(-target_amt)%>%
    filter(target_flag == 0) # obs not associated with automobile accidents

target_1 <- df%>%
    dplyr::select(-target_amt)%>%
    filter(target_flag == 1)  # obs associated with automobile accidents

# Calculate the proportion of data in each subset of target_flag

df %>%
    group_by(target_flag) %>%
    summarise(n = n()) %>%
    mutate(freq = n / sum(n))%>%
    flextable()%>%
    set_caption("Count and Frequency of Target Levels")

```
**1c. Summary Statistics for Numerical and Categorical Variables**

There is one negative value (-3) for car_age that should be investigated.This may be 
a data entry error.


```{r}

# Calculate statistics summary for numeric variables at each level of target_flag    

target_0%>%
    dplyr::select(-target_flag)%>%
    diagnose_numeric()%>%
    dplyr::select(variables, min, mean, median, max, zero, minus, outlier)%>%
    flextable()%>%
    set_caption("Summary Statistics for Target_Flag = 0")

target_1%>%
    dplyr::select(-target_flag)%>%
    diagnose_numeric()%>%
    dplyr::select(variables, min, mean, median, max, zero, minus, outlier)%>%
    flextable()%>%
    set_caption("Summary Statistics for Target_Flag = 1")

#Calculate percentage of zero values in numerical covariates for each level of target_flag

select_col<- as_mapper(~all(is.na(.)|.< 1)) # purrr mapper for possible downstream use

df%>%
    group_by(target_flag)%>%  # note target must be numerical type for the following to run
    dplyr::select(where(is.numeric) & -target_amt)%>%
    summarise_each(~round(sum(.==0)/length(.)*100))%>%
    purrr::discard(select_col)%>%
    flextable()%>%
    set_caption("Percentage of Zeros in Covariates by Level of Target_Flag")

# Create statistical summaries for categorical variables at each level of target_flag 

target_0%>%
    diagnose_category()%>%
    flextable(theme_fun = theme_booktabs())

target_1%>%
    diagnose_category()%>%
    flextable(theme_fun = theme_booktabs())

```
Correct obvious data entry error in working dataframe

```{r}

# Drop observation with data error for car age (obs. value = -3). 

df$car_age[df$car_age < 0] <- NA

```

**1d. Covariate Distributions**

skewed data - target_flag, kidsdriv, homekids, yoj, income, oldclaim, clm_freq, 
mvr_pts"


```{r}

# Evaluate and rank departures from normality for numerical vars

df %>%
    as.data.frame()%>%
    dplyr::select(-target_amt, target_flag)%>%
    normality() %>%
    filter(p_value <= 0.01) %>%
    arrange(abs(p_value))

#Identify skewness in covariates across levels of target_flag

target_0%>%find_skewness(index=FALSE, thres=TRUE) 
target_1%>%find_skewness(index=FALSE, thres=TRUE)

# Identify potential transformations to address skew, this does not resolve high 0 counts

df%>%
    dplyr::select(age, yoj, income, home_val, travtime, bluebook, tif, oldclaim, car_age)%>%
    plot_normality()

```
**1e. Data Outliers**

percentage of outliers > 5%: kidsdriv, homekids, yoj 

```{r}

# Identify percentage of outliers for each covariate across levels of target_flag
    

diagnose_outlier(target_0) %>%
    filter(outliers_ratio > 5)%>%
    mutate(ratio_means= outliers_mean/with_mean)%>% # mean val of outliers/total mean
    arrange(desc(ratio_means))%>%
    dplyr::select(variables, outliers_ratio, ratio_means)%>%
    flextable()%>%
    set_caption("Outlier Summary: Target_Flag = 0")

diagnose_outlier(target_1) %>%
    filter(outliers_ratio > 5)%>%
    mutate(ratio_means= outliers_mean/with_mean)%>%
    arrange(desc(ratio_means))%>%
    dplyr::select(variables, outliers_ratio, ratio_means)%>%
    flextable()%>%
    set_caption("Outlier Summary: Target_Flag = 1")
```

**1f. Missing Data**

Our dataset includes missing observations in one categorical variable (job) and six
numerical variables (car_age, home-val, yoj, income, age). Across the variables the
extent of missingness is < 6.5% of the total observations. Before making adjustments to
address missingness, it may be helpful to assess collinearity among the covariates. 


```{r }

#Basic missing table
    
target_0%>%
    diagnose()%>%
    dplyr::select(-unique_count, -unique_rate)%>%
    filter(missing_count>0)%>%
    arrange(desc(missing_count))%>%
    flextable()

target_1%>%
    diagnose()%>%
    dplyr::select(-unique_count, -unique_rate)%>%
    filter(missing_count>0)%>%
    arrange(desc(missing_count))%>%
    flextable()

# Plot missing data to visualize cumulative percentages and col intersections

p1<-df %>% 
  plot_na_pareto(only_na = TRUE)

p2<-df%>%
    plot_na_intersect()  

#print plots

(p1|p2)

```
**1g. Impute Missing Values**

Numerical variables
methods have been preselected based on initial plots.
Note: imputation method determined through iterative trials

```{r}

#Impute numerical vars using dlookr

#car_age

car_age<-imputate_na(df, car_age, target_flag, method = "mice", seed = 999)

p1<-plot(car_age)+theme_minimal()+theme(legend.position = "top")

summary(car_age)


#home_val


home_val<-imputate_na(df, home_val, target_flag, method = "rpart")

p2<-plot(home_val)+theme_minimal()+theme(legend.position = "top")

summary(home_val)

#yoj


yoj<- imputate_na(df, yoj, target_flag, method = "rpart")

p3<-plot(yoj)+theme_minimal()+theme(legend.position = "top")

summary(yoj)

# income

income<-imputate_na(df, income, target_flag, method = "rpart")

p4<-plot(income)+theme_minimal()+theme(legend.position = "top")

summary(income)

#age

age<-imputate_na(df, age, method = "rpart")

p5<-plot(age)+theme_minimal()+theme(legend.position = "top")

summary(age)

temp<-cbind(car_age, home_val, yoj, income, age)
temp%<>%as.data.frame(temp)

df%<>%dplyr::select(!c(car_age, home_val, yoj, income, age))%>%
    cbind(temp)

df%<>%mutate_if(is.numeric, round)

# print plots

(p1|p2)/(p3|p4)/p5

```

Categorical Variables - job

```{r}

job<-imputate_na(df, job, method = "mice", seed = 999)

plot(job)+theme_minimal()+theme(legend.position = "top")


# combine into new dfb

df<-df%>%
    dplyr::select(!job)

df<-cbind(df,job)

df$job<-factor(df$job)

```
Save csv with imputed values 

```{r}

#df%<>%mutate_at(vars(target_flag), funs(factor)) # convert target_flag to factor

#write.csv(df, 'df_clean.csv', row.names=FALSE)

```

**1h. Pairwise Comparisons**

Pairwise comparisons provide a method to identify collinear relationships between
covariates. Variables that display high collinearity (e.g., <> .50) may be redundant 
for modeling purposes (i.e., the total variance explained by each variable).

To refine the analyses, pairwise comparisons are assessed independently for the 
two levels of the target variable. 

Results:

* There are no pairwise correlations beyond the threshold (-.50, .50) for the target_flag = 1 subset
* home_value and income have a positive coeff. of correlation of ~ 0.59
* clm_freq and oldclaim have a positive coeff. of correlation of ~ 0.52

Both home_value and income have similar levels of missing data. An argument can be
made for dropping either home-value or income from the dataset in order to simplify 
the feature selection process. This is also true for clm_freq and oldclaim, although
less clear cut. 


```{r}

#Assess collinearity in the absence of zero values in numerical cols

df%>%
    filter_if(is.numeric, all_vars((.) != 0))%>%
    correlate()%>%
    filter(coef_corr > .5 | coef_corr < -.5)%>% # set thresholds to limit output 
    flextable()

# Plot relationship between numerical covariates (w/o zero values for clarity) beyond the threshold coef_corr 

p1<-df %>%
    filter(income != 0 & home_val != 0)%>% 
    target_by(income) %>%
    relate(home_val) %>%
    plot()
    

p2<-df %>%
    filter(clm_freq != 0 & oldclaim != 0)%>%
    target_by(clm_freq) %>%
    relate(oldclaim) %>%
    plot()

p3<-df %>%
    filter(home_val != 0 & car_age != 0)%>%
    target_by(home_val) %>%
    relate(car_age) %>%
    plot()

# Plot relationship between numerical and factors for select variables

p4<-df %>% 
  target_by(income) %>%      
  relate(job) %>% 
  plot()

df%>%kruskal.test(income~job) # assess covariance with Kruskal-Wallis rank sum test where > 1 categorical level

# Print plots

(p1|p2)/(p3|p4)

```

Categorical variables and target

Note: target_flag needs to be a factor var for mosaic plotting

Note: use all_of to avoid ambiguity in selecting external vector - https://tidyselect.r-lib.org/reference/faq-external-vector.html

Findings:

```{r }

# Subset categorical variables

df_factor<-df%>%
    dplyr::select(where(is.factor))

target <- all_of(names(df_factor)[1]) # set name for target_flag
covariates <- all_of(names(df_factor)[2:11]) # set names for factor covariates

#Create mosaic plots


(plots<-covariates%>%map(function(covariates) df%>%target_by(target)%>%relate(covariates)%>%plot()))

```
Numeric variables and target

```{r}

# Subset numerical variables

num_box<-select_if(df, is.numeric)%>%
    dplyr::select(-target_amt)

num_box<-cbind(df$target_flag, num_box)%>%
    rename(target_flag = 'df$target_flag')


# Plot using boxplots

response = names(num_box)[1] #target_flag
response = purrr::set_names(response)

explain <- names(num_box)[2:14] #explanatory variables
explain = purrr::set_names(explain)

box_fun = function(x) {
    ggplot(num_box, aes_string(x = x, y = 'target_flag') ) +
    geom_boxplot(aes(fill = target_flag, alpha = 0.4), outlier.color =
    'red', show.legend = FALSE)+
    scale_fill_viridis(discrete = TRUE, option = "E")+
    coord_flip()+
    theme_classic()
}

b_plots<-map(explain, ~box_fun(.x)) #creates a list of plots using purrr

ggarrange(plotlist=b_plots, height = .5, ncol = 3) # layout plots


```
**1i. Final Variable Selections**

```{r}

base_df<-df%>%
    dplyr::select(-home_val, -target_amt)  # variance in these fields explained by income

base_df%<>%
    mutate(job = (fct_collapse(job,
                 not_white_collar = c("Student", "Blue Collar", "Home Maker", "Clerical", "Manager"),
                 white_collar = c("Doctor", "Lawyer", "Professional"))))

#write.csv(base_df, 'base_df.csv', row.names=FALSE)    
```

##2. Training and Test Datasets##

use caret - rebalancing train for model building, test maintains relative freqs

```{r}
# Base_df<-read.csv('base_df.csv') # hold here to assist model dev 

base_df%>%count(target_flag)%>%
    mutate(frequency = n/sum(n))%>%
    flextable()  #--- > 0 = 6008, 1 = 2153

ones <- base_df%>%
    filter(target_flag == "1")

zeros <-base_df%>%
    filter(target_flag =="0")

set.seed(1234) 

# Build train/test sets; down-sample to re-balance test dataset

input_ones <- sample(1:nrow(ones), 0.7*nrow(ones))
input_zeros <- sample(1:nrow(zeros), 0.7*nrow(ones))

train_ones <- ones[input_ones, ]
train_zeros <- zeros[input_zeros, ]

train_df<-rbind(train_ones, train_zeros)

test_ones <- ones[-input_ones,]
test_zeros <- zeros[-input_zeros,]

test_df <- rbind(test_ones, test_zeros)

#Check counts and frequencies of target_flag for train set and test set 

train_df%>%count(target_flag)%>%
    mutate(frequency = n/sum(n))%>%
    flextable()

test_df%>%count(target_flag)%>%
    mutate(frequency = n/sum(n))%>%
    flextable()

```

##3. Build Models##

**3a. Null Model: Logistic Regression**

```{r}

null<-glm(target_flag ~ 1, family = binomial, train_df)

summary(null)

null_stats<-glance(null) # collect stats for model comparisons

```

**3b. Full Model: Logistic Regression**

```{r}

full<-glm(target_flag ~ ., family = binomial, train_df) 

summary(full)

full_stats<-glance(full) # collect stat metrics for model comparisons

```
**3c. Reduced Model: Logistic Regression **

```{r}

#Build reduced model

reduced <- glm(target_flag ~ .,family='binomial', train_df) 

reduced<-step(reduced, trace=0) # use Akiaike step for covariate selection, trace 0 prevents intermediate printing

summary(reduced)

reduced_stats<-glance(reduced) # collect stats for model comparisons

```
**3c.1. Diagnostics: Reduced Model**

The ROC curve shows the tradeoff between true positive rate and false positive rate across all cutoff values.

Note: InformationValue:confusionMatrix -- wants predicts and obs to be numerical, in caret they should be factor!

```{r}

# Collect predicted percentages

predicted<-predict(reduced,reduced_df,type='response')

# Find optimal threshold to minimize misclassification

optimal<- optimalCutoff(train_df$target_flag, predicted, optimiseFor = "misclasserror")  # 0.51

# Calculate training classification error with .51 threshold --> 0.2595

Miss_Class_Error<-misClassError(train_df$target_flag, predicted,  threshold = optimal)

# Convert predicted to 0, 1 values based on threshold

predicts<-ifelse(predicted >= optimal, 1, 0)

# Subset actuals and predicts as numeric for confusion matrix

actuals<-as.numeric(as.character(train_df$target_flag))

(InformationValue::confusionMatrix(actuals, predicts, threshold = optimal)) 

#Calculate related metrics

AUC<-AUROC(actuals, predicted) # -->.81

Sensitivity<-InformationValue::sensitivity(actuals, predicts, threshold = optimal) # recall: true positive rate
Specificity<-InformationValue::specificity(actuals, predicts, threshold = optimal) #false positive rate
Preciaion<-InformationValue::precision(actuals, predicts, threshold = optimal) # prop of predicted ones /prop total ones

YDI_Index<- youdensIndex(actuals, predicts, threshold = optimal) # 0.48 accounts for both false-positive and false-negative rates

# Assess predictive power using concordance

Predict_Power<-Concordance(actuals, predicts) # predictive power  ---> .548
Predict_Power<-Concord$Concordance

p1<-ks_plot(actuals, predicts) #cum perc of ones captured by the model against that expected random

ks_stat(actuals, predicts) #Kolmogorov-Smirnov statistic - maximum difference between the cumulative true positive and cumulative false positive rate

# Create a metrics table

reduced_metrics<-cbind(Predict_Power, Miss_Class_Error, AUC, Sensitivity, Specificity, Precision, YDI_Index, Kol_Smirnov)

# Construct ROC curve: note actuals, predicts, predicted as vectors)

pred <- ROCR::prediction(predicted, actuals)
perf <- ROCR::performance(pred, "tpr", "fpr")

p2<-plot(perf, colorize = TRUE, main = "ROC curve for logistic regression on insurance data")

#AUC curve

p3<-plotROC(actual, predicted)

(p1|p2|p3)

```

**3c.2. Reduced Model: Overdispersion**

- we are within tolerable levels of dispersion

```{r}

# Evaluate using deviance and quasibinomial comparison

deviance(reduced)/df.residual(reduced) # if considerably greater than one we should be concerned

# Check with two model fit

quasi_model <-  glm(target_flag ~ .,family='quasibinomial', base_df) # note: using base_df
  
pchisq(summary(quasi_model)$dispersion * reduced$df.residual,
 reduced$df.residual, lower = F)  
```
**3c.3. Reduced: Check linearity of numerical vars vs. logit***

Linearity is questionable for yoj, oldclaim

Note clustering in oldclaim - consider turning into 3-level factor?

```{r}

#create a dataframe for linearity analysis

reduced_df<-train_df

reduced_df$predicted<-predict(reduced,train_df,type='response') # add predicted

reduced_df%<>%mutate(logit = log(predicted/(1-predicted))) # add logit


# check linearity btwn numerical predictors and logit

p1<-with(reduced_df, scatter.smooth(travtime, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
p2<-with(reduced_df, scatter.smooth(tif, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
p3<-with(reduced_df, scatter.smooth(mvr_pts, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
p4<-with(reduced_df, scatter.smooth(income, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
p5<-with(reduced_df, scatter.smooth(homekids, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
p6<-with(reduced_df, scatter.smooth(oldclaim, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
p7<-with(reduced_df, scatter.smooth(clm_freq, logit, lpars = list(col = "red", lwd = 3, lty = 3)))
p8<-with(reduced_df, scatter.smooth(bluebook, logit, lpars = list(col = "red", lwd = 3, lty = 3)))

#Print Plots

(p1|p2|p3) /
(p4|p5|p6) /
(p7|p8)


```

**3c.4. Reduced Model: Outliers and Infuential obs**

computes the standardized residuals (.std.resid) and the Cookâ€™s distance (.cooksd) using the R function augment() [broom package]

See: http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r/

Findings:

Cooks distance indicates several standout obs (3722, 3592, 6501) but no influential points (id. D >1.0)

There are no obs has std residual beyond 3 stdev: 5101


```{r}

# Extract model results

reduced$data <- augment(reduced) %>% 
  mutate(index = 1:n()) 

# Identify Outliers

reduced$data %>% top_n(10, .cooksd)

p1<-plot(reduced, which = 4, id.n = 3)  # keep an eye on obs > 4/n 

#Plot Standardized Residuals

p2<-ggplot(reduced$data, aes(index, .std.resid)) + 
  geom_point(aes(color = target_flag), alpha = .5) +
  theme_bw()

#Filter potential influential data points with abs(.std.res) > 3

reduced$data %>% 
  filter(abs(.std.resid) > 3)

#Print plots

(p1|p2)
```
**3c.5. Reduced Model: Collinearity**

Findings: no problems with collinearity

```{r}

car::vif(reduced)
```

**3c.6. Reduced Model: Independence of Residuals**

We see some possible pattern (curvature) that might indicate misclassification but its unclear 

```{r }

resid_df<-train_df%>%mutate('residuals' = residuals(reduced), linpred = predict(reduced))

bins<- group_by(resid_df, cut(linpred, breaks=unique(quantile(linpred, (1:100)/101))))

diag<-summarize(bins, residuals=mean(residuals), linpred = mean(linpred))

plot(residuals~linpred, diag, xlab = "linear predictor")


```
**3d. Transfomed Model**


```{r fig.align='center', fig.height=10,fig.width=10, message = FALSE}


#Build model with transformed vars

trans <- glm( target_flag ~ kidsdriv + parent1 + mstatus + education + 
    log(travtime) + car_use + log(bluebook) + sqrt(tif) + car_type + (oldclaim) + 
    clm_freq + revoked + mvr_pts + urbanicity + sqrt(income) + age, family='binomial', train_df)

trans<-step(trans, trace=0) 

summary(trans)

trans_stats<-glance(trans) # save stats for model comparisons


```
**3d.1 Transformed Model: Diagnostics **

```{r}

# collect predicted percentages

trans_predicted<-predict(trans,train_df,type='response')

# find optimal threshold to minimize misclassification

(trans_optimal<- optimalCutoff(train_df$target_flag, trans_predicted, optimiseFor = "misclasserror"))  # 0.51

# calculate training classification error with .51 threshold --> 0.2588

Miss_Class_Error<-misClassError(train_df$target_flag, trans_predicted,  threshold = trans_optimal)

# convert predicted to 0, 1 values based on threshold

trans_predicts<-ifelse(trans_predicted >= trans_optimal, 1, 0)

# subset actuals and predicts as numeric for confusion matrix

trans_actuals<-as.numeric(as.character(optimum_df$target_flag))

(InformationValue::confusionMatrix(actuals, predicts, threshold = optimal))

#Calculate related metrics

AUC<-AUROC(trans_actuals, trans_predicted) # -->.81
Sensitivity<-InformationValue::sensitivity(actuals, predicts, threshold = optimal) # recall: true positive rate
Specificity<-InformationValue::specificity(actuals, predicts, threshold = optimal) #false positive rate
Precision<-InformationValue::precision(actuals, predicts, threshold = optimal) # prop of predicted ones /prop total ones
YDI_Index<-youdensIndex(actuals, predicts, threshold = optimal) # 0.48 accounts for both false-positive and false-negative rates

# Calculate predictive power using concordance

Concord<-Concordance(actuals, predicts)
Predict_Power<-Concord$Concordance

p1<-ks_plot(actuals, predicts) #cum perc of ones captured by the model against that expected random

Kol_Smirnov<-ks_stat(actuals, predicts) #Kolmogorov-Smirnov statistic - maximum difference between the cumulative true positive and cumulative false positive rate

# Create a metrics table

trans_metrics<-cbind(Predict_Power, Miss_Class_Error, AUC, Sensitivity, Specificity, Precision, YDI_Index, Kol_Smirnov)

# Construct ROC curve: note actuals, predicts, predicted as vectors)

pred <- ROCR::prediction(predicted, actuals)
perf <- ROCR::performance(pred, "tpr", "fpr")

p2<-plot(perf, colorize = TRUE, main = "ROC curve for logistic regression on insurance data")

#AUC curve

p3<-plotROC(actual, predicted)
```
##4. Model Selection##

```{r}

# Compare model output summaries

col_name<-c('Null Model', 'Full Model', 'Reduced Model', 'Transformed Model')

comp<-rbind(null_stats, full_stats, reduced_stats, trans_stats)

(compare_models<- cbind(col_name, comp)%>%
    dplyr::select(-c(null.deviance, df.null))%>%
    rename(Model = col_name)%>%
    flextable()%>%
     set_caption("Comparison of Model Results"))

# Compare select metrics for reduced and transformed models

col_final<-c('Reduced Model', 'Transformed Model')

final_comp<-rbind(reduced_metrics, trans_metrics)

(final_models<- cbind(col_final, final_comp)%>%
    as.data.frame()%>%
    mutate_at(vars(2:9), funs(as.numeric))%>%
    mutate_if(is.numeric, round, 3)%>%
    rename(Model = col_final)%>%
    flextable()%>%
    set_caption("Classification Metrics: Reduced & Transformed Models"))
```

##5. Model Evaluation##

```{r}

# Apply reduced model to test data

reduced_test<-glm(formula = target_flag ~ kidsdriv + parent1 + mstatus + 
    education+travtime + car_use + bluebook + tif + car_type + oldclaim + 
    clm_freq + revoked + mvr_pts + urbanicity + income + age, 
    family = "binomial", data = test_df)

# Apply fitted model to test sample (predicted probabilities)

predicted_test <- predict(reduced_test, test_df, type="response")

# Find optimal threshold to minimize misclassification

(test_optimal<- optimalCutoff(test_df$target_flag, predicted_test, optimiseFor = "Both"))

# Calculate training classification error with .51 threshold

Miss_Class_Error<-misClassError(test_df$target_flag, predicted_test,  threshold = test_optimal)

# Convert predicted to 0, 1 values based on threshold

predicts_test<-ifelse(predicted_test >= test_optimal, 1, 0)

# Cubset actuals and predicts as numeric for confusion matrix

actuals_test<-as.numeric(as.character(test_df$target_flag))

(InformationValue::confusionMatrix(actuals_test, predicts_test, threshold = test_optimal))

#Calculate related metrics

AUC<-AUROC(actuals_test, predicted_test) # -->.81
Sensitivity<-InformationValue::sensitivity(actuals_test, predicts_test, threshold = .17) # recall: true positive rate
Specificity<-InformationValue::specificity(actuals_test, predicts_test, threshold = .17) #false positive rate
Precision<-InformationValue::precision(actuals_test, predicts_test, threshold = .17) # prop of predicted ones /prop total ones
YDI_Index<-youdensIndex(actuals_test, predicts_test, threshold = test_optimal) # 0.48 accounts for both false-positive and false-negative rates

# Calculate predictive power using concordance

Concord<-Concordance(actuals_test, predicts_test)
Predict_Power<-Concord$Concordance

p1<-ks_plot(actuals_test, predicts_test) #cum perc of ones captured by the model against that expected random

Kol_Smirnov<-ks_stat(actuals_test, predicts_test) #Kolmogorov-Smirnov statistic - maximum difference between the cumulative true positive and cumulative false positive rate

# Create a metrics table

(test_metrics<-cbind(Predict_Power, Miss_Class_Error, AUC, Sensitivity, Specificity, Precision, YDI_Index, Kol_Smirnov)%>%
    as.data.frame()%>%
    mutate_at(vars(1:8), funs(as.numeric))%>%
    mutate_if(is.numeric, round, 3)%>%
    flextable()%>%
    set_caption("Reduced Model-Test Data: Metrics"))
    

# Construct ROC curve: note actuals, predicts, predicted as vectors)

pred <- ROCR::prediction(predicted_test, actuals_test)
perf <- ROCR::performance(pred, "tpr", "fpr")

p2<-plot(perf, colorize = TRUE, main = "ROC curve for logistic regression on insurance data")

#Construct AUC curve

p3<-plotROC(actuals_test, predicted_test)

# Print plots

(p1|p2|P3)
```
##6. Summary##

To be completed